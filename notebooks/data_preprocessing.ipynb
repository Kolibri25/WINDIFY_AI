{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rloSiKJjMe9Y"
      },
      "source": [
        "# Enviroment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCemtZtzguFF",
        "outputId": "3d5539db-e5e7-4f02-c16c-35992ffa1d24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'WINDIFY_AI'...\n",
            "remote: Enumerating objects: 141, done.\u001b[K\n",
            "remote: Counting objects: 100% (141/141), done.\u001b[K\n",
            "remote: Compressing objects: 100% (111/111), done.\u001b[K\n",
            "remote: Total 141 (delta 54), reused 74 (delta 21), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (141/141), 774.63 KiB | 4.50 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Kolibri25/WINDIFY_AI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R2__N0AgvYx",
        "outputId": "37a3ccc9-5505-4cc2-b930-1bb09be0626f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/WINDIFY_AI\n"
          ]
        }
      ],
      "source": [
        "cd WINDIFY_AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FffSfxEO_JIN"
      },
      "source": [
        "Setup environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kQSVikNd_Ii0",
        "outputId": "371c512e-5f43-444e-fc83-6796f2b69eac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting netCDF4==1.7.2 (from -r requirements.txt (line 1))\n",
            "  Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting numpy==1.23.5 (from -r requirements.txt (line 2))\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting pandas==1.5.3 (from -r requirements.txt (line 3))\n",
            "  Downloading pandas-1.5.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting xarray==2023.6.0 (from -r requirements.txt (line 4))\n",
            "  Downloading xarray-2023.6.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting scipy==1.10.1 (from -r requirements.txt (line 5))\n",
            "  Downloading scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests==2.28.1 (from -r requirements.txt (line 6))\n",
            "  Downloading requests-2.28.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting matplotlib==3.6.2 (from -r requirements.txt (line 7))\n",
            "  Downloading matplotlib-3.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting dask==2023.6.0 (from -r requirements.txt (line 8))\n",
            "  Downloading dask-2023.6.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting torch==1.13.0 (from -r requirements.txt (line 9))\n",
            "  Downloading torch-1.13.0-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "\u001b[31mERROR: Ignored the following yanked versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.15.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11; 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 1.7.2 Requires-Python >=3.7,<3.11; 1.7.3 Requires-Python >=3.7,<3.11; 1.8.0 Requires-Python >=3.8,<3.11; 1.8.0rc1 Requires-Python >=3.8,<3.11; 1.8.0rc2 Requires-Python >=3.8,<3.11; 1.8.0rc3 Requires-Python >=3.8,<3.11; 1.8.0rc4 Requires-Python >=3.8,<3.11; 1.8.1 Requires-Python >=3.8,<3.11\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision==0.14.0 (from versions: 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.16.2, 0.17.0, 0.17.1, 0.17.2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 0.20.0, 0.20.1, 0.21.0, 0.22.0, 0.22.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchvision==0.14.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install netCDF4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0UIrfCSJ68N",
        "outputId": "bd9e18ec-895f-470f-a958-91642762efb3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting netCDF4\n",
            "  Using cached netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting cftime (from netCDF4)\n",
            "  Downloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netCDF4) (2025.7.14)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from netCDF4) (2.0.2)\n",
            "Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cftime, netCDF4\n",
            "Successfully installed cftime-1.6.4.post1 netCDF4-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EMv_nCdHD_u2"
      },
      "outputs": [],
      "source": [
        "import scripts.download_barra as dnb\n",
        "import scripts.load_data as ld\n",
        "from scripts.model_input import create_uv_tensor, create_uv_tensor_era5, split_tensor\n",
        "import models.unet_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OqKDxy0kDIg5"
      },
      "outputs": [],
      "source": [
        "import xarray as xr\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ_7p29H-w3r"
      },
      "source": [
        "Below purely to document BARRA data download and import procedure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mDEF4P5J-wNa",
        "outputId": "736f4716-ab03-4a2d-eeff-7bc688a6c9b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n# download barrac2 data from months of Oct, Nov, Dec, Jan from 1979 to 2024\\n# lat/lon values and variables are hard-coded in the script\\n# need to check download path\\n\\ndnb.main()\\n\\n# download era5\\n# TODO: write script to download era5 data\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "'''\n",
        "\n",
        "# download barrac2 data from months of Oct, Nov, Dec, Jan from 1979 to 2024\n",
        "# lat/lon values and variables are hard-coded in the script\n",
        "# need to check download path\n",
        "\n",
        "dnb.main()\n",
        "\n",
        "# download era5\n",
        "# TODO: write script to download era5 data\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Eo32avi0-5Ws"
      },
      "outputs": [],
      "source": [
        "## combine files into single dataset per variable\n",
        "## BARRA-C2\n",
        "#ld.load_and_save_barra_c2()\n",
        "## ERA5\n",
        "#ld.load_and_save_era5()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O-0p6e5EqGI"
      },
      "source": [
        "Importing previously downloaded data using gdown from Google Drive folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0Z95sG3gE0ca",
        "outputId": "6f3c0f94-bf06-41b8-b562-65f0c0d93baf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.7.14)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Retrieving folder contents\n",
            "Retrieving folder 1f2DGtE-oKAuXlnp2re9byp4UbMitIFOf BARRA-C2\n",
            "Processing file 1MPIFRs3SoilpeLTMn7P21NyiRAOyZNIB uas_gesamt.nc\n",
            "Processing file 1hkWS9IlTFCIS0BGv0Yl0WbgkILRsaPa_ vas_gesamt.nc\n",
            "Retrieving folder 1_rHNYO880eYBNB0w7ciNWKxCop2oq4Na ERA5\n",
            "Processing file 1biSKBWzXjYk8e7UWYl-QJs-bP4z0FWqe combined_era5.nc\n",
            "Retrieving folder 1L-QsfJgqixDRWQHN6jxEkWdid0-YjZtX processed_data\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1MPIFRs3SoilpeLTMn7P21NyiRAOyZNIB\n",
            "From (redirected): https://drive.google.com/uc?id=1MPIFRs3SoilpeLTMn7P21NyiRAOyZNIB&confirm=t&uuid=cd610533-eb71-4566-b23a-28763245b78d\n",
            "To: /content/WINDIFY_AI/metfut_data/BARRA-C2/uas_gesamt.nc\n",
            "100% 1.72G/1.72G [00:13<00:00, 123MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1hkWS9IlTFCIS0BGv0Yl0WbgkILRsaPa_\n",
            "From (redirected): https://drive.google.com/uc?id=1hkWS9IlTFCIS0BGv0Yl0WbgkILRsaPa_&confirm=t&uuid=f2ecd69f-ffdf-42a8-b2a1-17dd854e13d2\n",
            "To: /content/WINDIFY_AI/metfut_data/BARRA-C2/vas_gesamt.nc\n",
            "100% 1.56G/1.56G [00:12<00:00, 123MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1biSKBWzXjYk8e7UWYl-QJs-bP4z0FWqe\n",
            "To: /content/WINDIFY_AI/metfut_data/ERA5/combined_era5.nc\n",
            "100% 70.3M/70.3M [00:00<00:00, 75.6MB/s]\n",
            "Download completed\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown\n",
        "!gdown --folder https://drive.google.com/drive/folders/1xwqJ8Ku_US5Q7MRvExKC26TqCUroQ6QE?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHB-fSBwv4Q5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-lKr0vQ6v1VL"
      },
      "outputs": [],
      "source": [
        "!mv metfut_data/* /content/WINDIFY_AI/data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QEpkVf5yr2Ty"
      },
      "outputs": [],
      "source": [
        "# load target data (BARRA-C2)\n",
        "\n",
        "uas_ds = xr.open_dataset('/content/WINDIFY_AI/data/BARRA-C2/uas_gesamt.nc')\n",
        "vas_ds = xr.open_dataset('/content/WINDIFY_AI/data/BARRA-C2/vas_gesamt.nc')\n",
        "\n",
        "# load input data (ERA5)\n",
        "\n",
        "era5_ds = xr.open_dataset('/content/WINDIFY_AI/data/ERA5/combined_era5.nc')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSeJUldbMjQe"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eq-QjBe-m133"
      },
      "source": [
        "Steps for Target ie. BARRA-C2:\n",
        "\n",
        "1. Drop grid points to match model dimensions (divisible by 16).\n",
        "2. Normalise the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMM0GGSH1D7f"
      },
      "source": [
        "Steps for Input ie. ERA5\n",
        "\n",
        "1.   Drop grid points to match model dimensions (divisible by 16).\n",
        "2.   Regrid EAR5 to a high-resolution grid of BARRA-C2\n",
        "3.  Normalise the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhM8QYTj3QEY"
      },
      "source": [
        "Finally, we stack the input/target together as PyTorch tensors and split the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH0x6Yufrqx2"
      },
      "source": [
        "## Target: BARRA-C2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "y6BpIEUdrvi_"
      },
      "outputs": [],
      "source": [
        "# crop to make dimensions divisible by 16\n",
        "\n",
        "from scripts.crop_to_div16 import crop_to_multiple_of_16\n",
        "\n",
        "uas_ds = crop_to_multiple_of_16(uas_ds, lat_name='lat', lon_name='lon')\n",
        "vas_ds = crop_to_multiple_of_16(vas_ds, lat_name='lat', lon_name='lon')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_gwRuR1-3oRZ"
      },
      "outputs": [],
      "source": [
        "# normalise the target data\n",
        "\n",
        "from scripts.normalize_data import normalize_data\n",
        "\n",
        "uas_ds, uas_mean, uas_std = normalize_data(uas_ds,\"uas\")\n",
        "vas_ds, vas_mean, vas_std = normalize_data(vas_ds,\"vas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Owb5KRxM5Fq7"
      },
      "source": [
        "## Input: ERA5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GTquY7ZZ5I9p"
      },
      "outputs": [],
      "source": [
        "# regrid to barra grid\n",
        "\n",
        "era5_interp = era5_ds.interp(\n",
        "    latitude=uas_ds.lat,\n",
        "    longitude=uas_ds.lon,\n",
        "    method='nearest'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rWMs_VyO5VSd"
      },
      "outputs": [],
      "source": [
        "# normalise input data\n",
        "\n",
        "u10_ds, u10_mean, u10_std = normalize_data(era5_interp,\"u10\")\n",
        "v10_ds, v10_mean, v10_std = normalize_data(era5_interp,\"v10\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVEA0m8y7EQ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f517223d-29bf-4ee2-da3d-81a24f0ca196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of uas_ds: (144,)\n",
            "Shape of vas_ds: (144,)\n",
            "uas_ds longitude values: [146.1  146.14 146.18 146.22 146.26 146.3  146.34 146.38 146.42 146.46\n",
            " 146.5  146.54 146.58 146.62 146.66 146.7  146.74 146.78 146.82 146.86\n",
            " 146.9  146.94 146.98 147.02 147.06 147.1  147.14 147.18 147.22 147.26\n",
            " 147.3  147.34 147.38 147.42 147.46 147.5  147.54 147.58 147.62 147.66\n",
            " 147.7  147.74 147.78 147.82 147.86 147.9  147.94 147.98 148.02 148.06\n",
            " 148.1  148.14 148.18 148.22 148.26 148.3  148.34 148.38 148.42 148.46\n",
            " 148.5  148.54 148.58 148.62 148.66 148.7  148.74 148.78 148.82 148.86\n",
            " 148.9  148.94 148.98 149.02 149.06 149.1  149.14 149.18 149.22 149.26\n",
            " 149.3  149.34 149.38 149.42 149.46 149.5  149.54 149.58 149.62 149.66\n",
            " 149.7  149.74 149.78 149.82 149.86 149.9  149.94 149.98 150.02 150.06\n",
            " 150.1  150.14 150.18 150.22 150.26 150.3  150.34 150.38 150.42 150.46\n",
            " 150.5  150.54 150.58 150.62 150.66 150.7  150.74 150.78 150.82 150.86\n",
            " 150.9  150.94 150.98 151.02 151.06 151.1  151.14 151.18 151.22 151.26\n",
            " 151.3  151.34 151.38 151.42 151.46 151.5  151.54 151.58 151.62 151.66\n",
            " 151.7  151.74 151.78 151.82]\n",
            "vas_ds longitude values: [145.98 146.02 146.06 146.1  146.14 146.18 146.22 146.26 146.3  146.34\n",
            " 146.38 146.42 146.46 146.5  146.54 146.58 146.62 146.66 146.7  146.74\n",
            " 146.78 146.82 146.86 146.9  146.94 146.98 147.02 147.06 147.1  147.14\n",
            " 147.18 147.22 147.26 147.3  147.34 147.38 147.42 147.46 147.5  147.54\n",
            " 147.58 147.62 147.66 147.7  147.74 147.78 147.82 147.86 147.9  147.94\n",
            " 147.98 148.02 148.06 148.1  148.14 148.18 148.22 148.26 148.3  148.34\n",
            " 148.38 148.42 148.46 148.5  148.54 148.58 148.62 148.66 148.7  148.74\n",
            " 148.78 148.82 148.86 148.9  148.94 148.98 149.02 149.06 149.1  149.14\n",
            " 149.18 149.22 149.26 149.3  149.34 149.38 149.42 149.46 149.5  149.54\n",
            " 149.58 149.62 149.66 149.7  149.74 149.78 149.82 149.86 149.9  149.94\n",
            " 149.98 150.02 150.06 150.1  150.14 150.18 150.22 150.26 150.3  150.34\n",
            " 150.38 150.42 150.46 150.5  150.54 150.58 150.62 150.66 150.7  150.74\n",
            " 150.78 150.82 150.86 150.9  150.94 150.98 151.02 151.06 151.1  151.14\n",
            " 151.18 151.22 151.26 151.3  151.34 151.38 151.42 151.46 151.5  151.54\n",
            " 151.58 151.62 151.66 151.7 ]\n"
          ]
        }
      ],
      "source": [
        "# convert to PyTorch tensors\n",
        "\n",
        "print(\"Shape of uas_ds:\", uas_ds.lon.shape)\n",
        "print(\"Shape of vas_ds:\", vas_ds.lon.shape)\n",
        "print(\"uas_ds longitude values:\", uas_ds.lon.values)\n",
        "print(\"vas_ds longitude values:\", vas_ds.lon.values)\n",
        "\n",
        "# Interpolate vas_ds to match uas_ds longitude coordinates\n",
        "vas_ds_interp = vas_ds.interp(lon=uas_ds.lon, method='nearest')\n",
        "\n",
        "target = create_uv_tensor(uas_ds,vas_ds_interp)\n",
        "input = create_uv_tensor_era5(u10_ds[\"u10\"],v10_ds[\"v10\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OwrpaCT9joE"
      },
      "outputs": [],
      "source": [
        "# check shapes\n",
        "\n",
        "print(target.shape)\n",
        "print(input.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnBb_hlM9BMW"
      },
      "outputs": [],
      "source": [
        "# save in case of runtime shortage\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "output_path = \"/content/drive/MyDrive/metfut_data/processed_data/\"\n",
        "\n",
        "import os\n",
        "\n",
        "# Ensure trailing slash and directory exists\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# Use os.path.join to avoid hardcoding slashes\n",
        "torch.save(target, os.path.join(output_path, 'target.pt'))\n",
        "torch.save(input, os.path.join(output_path, 'input.pt'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vzXbYPR9UHn"
      },
      "outputs": [],
      "source": [
        "# train/validation/test split\n",
        "\n",
        "x_train, x_val, x_test = split_tensor(input)\n",
        "y_train, y_val, y_test = split_tensor(target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HffKdy7Y63S1"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}